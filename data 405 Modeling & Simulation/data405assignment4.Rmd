---
title: "Data 405 Assignment 4 2025W"
output:
  pdf_document: default
  html_document: default
date: "2025-9-25"
---


# Data 405 Assignment 4

## Q1 code:

```{r}

set.seed(2025)

# load data
data(EuStockMarkets)
DAX <- EuStockMarkets[, "DAX"]

# (a) store dat in object
DAXlogreturn <- diff(log(DAX))

# (b) find drift (the mean of log-returns)
drift <- mean(DAXlogreturn)

# (c) acf of log-returns (the lin dependence)
pdf(NULL)
ansc <- acf(DAXlogreturn, main = "ACF of DAX log-returns")
ansc

# (d) acf of log-returns ^2 (prove of ARCH)
ansd <- acf(DAXlogreturn^2, main = "ACF of ^2 DAX log-returns")
ansd

# (e) fit AR(2) to ^2 returns to obtain approx ARCH(2) parameters
out <- arima(DAXlogreturn^2, order = c(2, 0, 0), include.mean=TRUE)
print(out)

# extract coef
phi <- as.numeric(out$coef[1:2])     # phi1, phi2 from AR(2) on ^2 series
xbar <- as.numeric(out$coef["intercept"]) # intercept (mean) from arima on ^2 series
s2 <- out$sigma2
cat("phi1 =", phi[1], " phi2 =", phi[2], " intercept =", xbar, " sigma2 =", s2, "\n")

# write out fitted AR(2) model for ^2 returns:
# y_t^2 = intercept + phi1 * y_{t-1}^2 + phi2 * y_{t-2}^2 + error_t
cat("\nfitted AR(2) on ^2 returns:\n")
cat(sprintf("y_t^2 = %g + (%g) y_{t-1}^2 + (%g) y_{t-2}^2 + eps_t\n",
            xbar, phi[1], phi[2]))

# (f) approximate ARCH(2) model using phi estimates:
# conditional variance: a0 + a1*y_{t-1}^2 + a2*y_{t-2}^2
# where a0 = intercept, a1 = phi1, a2 = phi2 (approx)

cat("\nApproximate ARCH(2):\n")
cat(sprintf("sigma_t^2 = %g + %g * y_{t-1}^2 + %g * y_{t-2}^2\n", xbar, phi[1], phi[2]))

```


### Q1b

Mean log-return (drift): `0.0006520417`

### Q1c ACF of raw returns:

No meaningful autocorrelation. All values are near 0. Conclusion: No linear dependence.

### Q1d, ACF of squared returns:

Clear positive autocorrelation at lag 1 (~0.079) and lag 2 (~0.171), and smaller positive values at later lags.
Conclusion: Strong evidence of volatility clustering.

### Q1e AR(2) fit:

```
y_t^2 = 0.000106487
+ 0.0658011 * y_{t-1}^2
+ 0.166083  * y_{t-2}^2
+ eps_t
```

### Q1f Approximate ARCH model:

```
σ_t^2 = 0.000106487
+ 0.166083  * y_{t-2}^2
+ 0.0658011 * y_{t-1}^2
```

### Q1g:

``` {r}
# (g) simulate a time series with same length and include drift
n <- length(DAX)
y <- numeric(n)
# init first two values with actual first two log-returns
y[1:2] <- DAXlogreturn[1:2]
Z <- rnorm(n)

for (i in 3:n) {
  condvar <- xbar + phi[1]*y[i-1]^2 + phi[2]*y[i-2]^2
  condvar <- ifelse(condvar > 0, condvar, 1e-8) # guard against tiny/negative
  s <- sqrt(condvar) * Z[i]
  y[i] <- s
}

# add drift & re-accumulate to prices
y_with_drift <- c(log(DAX[1]), y + drift)
DAXsim <- exp(cumsum(y_with_drift))

# plot real vs simulated
par(mfrow = c(1,2))
ts.plot(DAX, main = "Original DAX", ylab = "Index")
ts.plot(DAXsim, main = "Simulated DAX (ARCH(2) approx)", ylab = "Index")
par(mfrow = c(1,1))

# quick diagnostics: compare empirical acf of ^2 returns real vs simulated
par(mfrow = c(1,2))
acf(DAXlogreturn^2, main = "ACF ^2 (original)")
acf((diff(log(DAXsim)))^2, main = "ACF ^2 (simulated)")
par(mfrow = c(1,1))

# prin summary outputs
cat("\ndrift (mean log-return):", drift, "\n")
cat("length of series N:", n)

```

output:

```
drift (mean log-return): 0.0006520417 
length of series N: 1860
```

see data405assignment4q1ga.png and data405assignment4q1gb.png for plots 


## Q2:

```{r}
CAC <- EuStockMarkets[,3]

# Log returns
CAClogreturn <- diff(log(CAC))

# Fit ARCH(2) by fitting AR(2) to 2 returns
fit <- arima(CAClogreturn^2, order=c(2,0,0), include.mean=TRUE)

phi1 <- fit$coef[1]
phi2 <- fit$coef[2]
a0   <- fit$coef[3]
N    <- length(CAClogreturn)

sim <- numeric(N)
sim[1:2] <- CAClogreturn[1:2]
Z <- rnorm(N)

for(i in 3:N){
  sigma2 <- a0 + phi1 * sim[i-1]^2 + phi2 * sim[i-2]^2
  sim[i] <- sqrt(sigma2) * Z[i]
}

# Load CAC data (3rd column)
CAC <- EuStockMarkets[,3]

# Log returns
CAClogreturn <- diff(log(CAC))

# Fit ARCH(2) by fitting AR(2) to squared returns
fit <- arima(CAClogreturn^2, order=c(2,0,0), include.mean=TRUE)

phi1 <- fit$coef[1]
phi2 <- fit$coef[2]
a0   <- fit$coef[3]
N    <- length(CAClogreturn)

# Simulate ARCH(2)
sim <- numeric(N)
sim[1:2] <- CAClogreturn[1:2]
Z <- rnorm(N)

for(i in 3:N){
  sigma2 <- a0 + phi1 * sim[i-1]^2 + phi2 * sim[i-2]^2
  sim[i] <- sqrt(sigma2) * Z[i]
}

sim_prices <- exp(cumsum(c(log(CAC[1]), sim)))

# plot time
par(mfrow=c(1,2))
ts.plot(CAC, main="Original CAC")
ts.plot(sim_prices, main="Simulated ARCH(2) CAC")
sim_prices <- exp(cumsum(c(log(CAC[1]), sim)))

# Plots
par(mfrow=c(1,2))
ts.plot(CAC, main="Original CAC")
ts.plot(sim_prices, main="Simulated ARCH(2) CAC")


```


## Q3:

``` {r}
# we simulate 100000 weeks and estimate annual probability > 250.
set.seed(2025)

p <- c(0.3,0.1,0.3,0.2,0.1)   # p0..p4
y <- 0:4
states <- 0:10

# a transition matrix P
P <- matrix(0, nrow=11, ncol=11)
for (i in states) {
  after <- max(i - 2, 0)
  for (k in seq_along(y)) {
    j <- after + y[k]
    if (j > 10) j <- 10
    P[i+1, j+1] <- P[i+1, j+1] + p[k]
  }
}
rownames(P) <- colnames(P) <- as.character(states)

# 3b check regularity: compute P^50 and see if positive
P50 <- P ^50  # requires expm package; if not installed use eigen method below

# 3c stationary distribution pi (left eigenvector)
eig <- eigen(t(P))
idx <- which.min(abs(eig$values - 1))
pi <- Re(eig$vectors[,idx])
pi <- pi / sum(pi)

# 3d long-run weekly cost
costs <- 2 + 5 * pmax(0, 2 - states)      # weekly cost per state
long_run_weekly_cost <- sum(pi * costs)

# 3ef simulate 100000 weeks, compute annual (52-week) total costs,
#         estimate P(annual cost > 250)
nweeks <- 100000
X <- integer(nweeks)
X[1] <- 5
for (t in 2:nweeks) {
  after <- max(X[t-1] - 2, 0)
  ydraw <- sample(0:4, 1, prob = p)
  X[t] <- min(after + ydraw, 10)
}

weeks_per_year <- 52
nyears <- floor(nweeks / weeks_per_year)
annual_costs <- numeric(nyears)
for (k in 1:nyears) {
  block <- X[((k-1)*weeks_per_year + 1):(k*weeks_per_year)]
  weekly <- 2 + 5 * pmax(0, 2 - block)
  annual_costs[k] <- sum(weekly)
}
prob_exceed <- mean(annual_costs > 250)

# print result
print("Transition matrix P:")
print(round(P, 3))
cat("\nStationary distribution pi (length 11):\n")
print(round(pi, 9))
cat("\nLong-run weekly cost:", round(long_run_weekly_cost, 6), "\n")
cat("Estimated P(annual cost > 250):", round(prob_exceed, 6), "\n")
cat("Sample mean annual cost:", round(mean(annual_costs),4),
    " sd:", round(sd(annual_costs),4), "\n")
```


**b Regularity:** The chain is irreducible and aperiodic (some power of P has all positive entries), so the transition matrix is regular.

**d Long-run average weekly cost:**  
`E[cost] = 3.563752058457253` units per week (where weekly cost = 2 + 5*max(0,2 - state)).

**e-f Simulation (100000 weeks):**  
- Sample mean annual cost ≈ `183.9298`, sd ≈ `42.07`.  
- Estimated probability that annual cost > 250 (from simulation) ≈ **0.0598024** (≈ 5.98%).


## Q4:

``` {r}
FTSE <- EuStockMarkets[,4]
n <- length(FTSE)
lFTSE <- log(FTSE)
logreturns <- diff(lFTSE)
logreturnsQ <- c(min(logreturns)*1.01,
quantile(logreturns, (1:9)/10), max(logreturns)*1.01)
logreturnsCut <- cut(logreturns, logreturnsQ)
levels(logreturnsCut) <- 1:10


# 4b: ts plot

plot(FTSE, type="l", main="FTSE index (full series)", ylab="Index")
abline(v=1000, col="red")   # mark 1000th
abline(v=n, col="blue")     # mark -1 st




```




``` {R}

# 4c

P <- matrix(c(1:4, 4:1, 1,4,4,1,4,1,4,1), nrow=4, byrow=TRUE)/10
PE <- matrix(c(1:10, 10:1, rep(5.5,10), c(rep(1,5), rep(10,5))), nrow=4, byrow=TRUE)/55
rownames(P) <- paste0("S",1:4); colnames(P) <- paste0("S",1:4)
rownames(PE) <- paste0("S",1:4); colnames(PE) <- as.character(1:10)
P
PE

# 4de
# install.packages("HMM")
library("HMM")

# initialize HMM (states=1:4, symbols=1:10) and run Baum-Welch on first 1000 obs
hmm0 <- initHMM(
  States       = as.character(1:4),
  Symbols      = as.character(1:10),
  startProbs   = rep(1/4, 4),
  transProbs   = P,
  emissionProbs = PE
)

obsTrain <- as.character(as.numeric(logreturnsCut[1:1000]))
bw <- baumWelch(hmm0, observation = obsTrain, maxIterations = 100, delta = 1e-6)
hmmFit <- list(hmm = bw$hmm, logLik = bw$logProb)


```



``` {R}

# 4f

nTraining <- 1000
N <- 1000
nTesting <- n - nTraining
Index859 <- numeric(N)
for (i in 1:N) {
index <- as.numeric(simHMM(hmmFit$hmm, nTesting)$observation)
Index859[i] <- exp(cumsum(c(log(FTSE[nTraining]), runif(nTesting,
min=logreturnsQ[index], max=logreturnsQ[index+1]))))[nTesting]
}

# hist time
hist(Index859, breaks=50, freq=FALSE, main="Simulated FTSE at time 1859 (from t=1000)", xlab="FTSE (simulated)")
rug(FTSE[n])   # actual final value
abline(v = FTSE[n], col="red", lwd=2)
# option price (strike = 5000)
option_price_1000 <- mean((Index859 - 5000) * (Index859 > 5000))

```

``` {R}
option_price_1000
```

**Interpretation:** These values seem realistic considering the distribution is normally distributed with an expected kertosis (as a value cannot be negative AFAIK). Additionally the expected varrience for the higher senarios looks accurate




```{R}
# g
nTraining2 <- 1829
nTesting2 <- 1859 - nTraining2   # = 30

N <- 1000
Index1859_from1829 <- numeric(N)
for (i in 1:N) {
  sim_res <- simHMM(hmmFit$hmm, nTesting2)
  index <- as.numeric(sim_res$observation)
  uvals <- runif(nTesting2, min = logreturnsQ[index], max = logreturnsQ[index + 1])
  Index1859_from1829[i] <- exp( cumsum(c(log(FTSE[nTraining2]), uvals))[nTesting2 + 1] )
}

hist(Index1859_from1829, breaks=40, freq=FALSE, main="Simulated FTSE at time 1859 (from t=1829)", xlab="FTSE (simulated)")
rug(FTSE[1859])
abline(v=FTSE[1859], col="red", lwd=2)

option_price_1829 <- mean((Index1859_from1829 - 5000) * (Index1859_from1829 > 5000))

```

``` {R}
option_price_1000
```



## Q5:


``` {R}

# a. 40^2 matrix
dice_freq <- c(`2`=1, `3`=2, `4`=3, `5`=4, `6`=5, `7`=6, `8`=5, `9`=4, `10`=3, `11`=2, `12`=1)
dice_p <- dice_freq / sum(dice_freq)

states <- 1:40
P <- matrix(0, nrow=40, ncol=40)
for (i in states) {
  if (i == 31) {    ##### space 31 -> next move to 11
    P[i, 11] <- 1
  } else {
    for (s in 2:12) {
      j <- ((i - 1) + s) %% 40 + 1
      P[i, j] <- P[i, j] + dice_p[as.character(s)]
    }
  }
}

# b - vector
eig <- eigen(t(P))
idx <- which.min(abs(eig$values - 1))
pi <- Re(eig$vectors[, idx])
pi <- pi / sum(pi)
names(pi) <- as.character(states)

# barplot of probs
barplot(pi, main="Stationary distribution (Monopoly simplified)", xlab="Space", ylab="PI")

# which space is second-most frequently visited?
ord <- order(pi, decreasing = TRUE)
most_space <- ord[1]
second_space <- ord[2]
space40_prob <- pi["40"]





```


``` {R}

# c E[ revenue per turn from hotels on spaces 17,19,20 ]
revenue_per_turn <- pi["17"]*950 + pi["19"]*950 + pi["20"]*1000

# print res
cat("Most visited space:", most_space, "\n")
cat("2nd-most visited space:", second_space, "\n")
cat("Visit probability for space 40:", round(as.numeric(space40_prob), 6), "\n")
cat("Expected revenue per turn from hotels:", round(as.numeric(revenue_per_turn), 6), "\n")

```


``` {R}

# d&e:
